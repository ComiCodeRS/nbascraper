{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by creating a list that contains all the years using the range function. Because the last number is not included by the range function, I use range(1991, 2023) to generate a list from 1991 to 2022. The end parameter is used to print the list horizontally so that you don’t have to scroll all the way down to confirm you have the correct output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022] "
     ]
    }
   ],
   "source": [
    "years = list(range(1991, 2023))\n",
    "print(years, end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to find the page with the data we need and assign its URL to a variable. This is the format of the original URL (https://www.basketball-reference.com/awards/awards_1991.html). Just replace the curly brace with any year between 1991 and 2022to access the specific web page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_start = \"https://www.basketball-reference.com/awards/awards_{}.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The curly brace in the URL will hold the respective years that we will iterate through as we download the HTML pages. We will use the requests library to make a request to the website to download the web pages we want.\n",
    "\n",
    "Create a folder called MVP or your preferred name. Make sure it is in the same directory as the one used to run your notebook otherwise, you will be forced to write the full path to your folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # make a request to the webpage to download it\n",
    "import time\n",
    "\n",
    "for year in years:\n",
    "    # create a url for a specific year\n",
    "    url = url_start.format(year)\n",
    "    data = requests.get(url)\n",
    "    \n",
    "    # W+ opens file in write mode and if it already exists it will just overwrite.\n",
    "    with open(\"MVP/{}.html\".format(year), \"w+\", encoding = \"utf-8\") as f:\n",
    "        time.sleep(3)\n",
    "        f.write(data.text) #text saves files as html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid character encoding errors, specify the encoding as utf-8. The time.sleep(3) is used to delay making requests to the browser for 3 seconds after downloading the web page for each year to prevent overloading the website’s server. You can increase the number of seconds if you wish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We parse the table using the Beautiful Soup library. We will first parse and extract data from a single page to ensure that we are doing it correctly, and then repeat for the remaining years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import beautiful soup\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# read the HTML data\n",
    "with open(\"MVP/1991.html\", encoding=\"utf-8\") as f:\n",
    "    page = f.read()\n",
    "\n",
    "# create a parser class to extract table from the page\n",
    "soup = BeautifulSoup(page, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To scrape the data, we need to find the tag elements of the table. We do this by inspecting the webpage. Right-click anywhere on the webpage and select Inspect. This displays the HTML code for the page and when you hover over it, it will highlight different elements of the page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the table, we can see that there is an extra header row. We need to remove this row because when we load the table data in pandas, it will create an extra header row that is unnecessary. Afterward, we find the specific table whose data we want to extract.\n",
    "\n",
    "We use beautiful soup’s find function to find the header element which is in a <tr> tag with a class of “over_header”. Because class is a reserved keyword in Python and using it will result in a syntax error, we use an underscore after it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header row removed successfully\n"
     ]
    }
   ],
   "source": [
    "# remove the top row of the table\n",
    "soup.find(\"tr\", class_=\"over_header\").decompose()\n",
    "print(\"Header row removed successfully\")\n",
    "\n",
    "# find the specific table we want using its id\n",
    "mvp_table = soup.find(id=\"mvp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decompose function removes a tag as well as its inner content. We find the specific table we want using the id. This is because in HTML the id is a globally unique property in HTML that only one element should have.\n",
    "\n",
    "Finally, we read the table into pandas. By default, it is not read as a string so we use the str( ) function to convert it into a string. The result will be a list of data frames which is not what we want. So we get the first index thus the [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Player</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tm</th>\n",
       "      <th>First</th>\n",
       "      <th>Pts Won</th>\n",
       "      <th>Pts Max</th>\n",
       "      <th>Share</th>\n",
       "      <th>G</th>\n",
       "      <th>MP</th>\n",
       "      <th>PTS</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FT%</th>\n",
       "      <th>WS</th>\n",
       "      <th>WS/48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Michael Jordan</td>\n",
       "      <td>27</td>\n",
       "      <td>CHI</td>\n",
       "      <td>77.0</td>\n",
       "      <td>891.0</td>\n",
       "      <td>960</td>\n",
       "      <td>0.928</td>\n",
       "      <td>82</td>\n",
       "      <td>37.0</td>\n",
       "      <td>31.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.851</td>\n",
       "      <td>20.3</td>\n",
       "      <td>0.321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Magic Johnson</td>\n",
       "      <td>31</td>\n",
       "      <td>LAL</td>\n",
       "      <td>10.0</td>\n",
       "      <td>497.0</td>\n",
       "      <td>960</td>\n",
       "      <td>0.518</td>\n",
       "      <td>79</td>\n",
       "      <td>37.1</td>\n",
       "      <td>19.4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.906</td>\n",
       "      <td>15.4</td>\n",
       "      <td>0.251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>David Robinson</td>\n",
       "      <td>25</td>\n",
       "      <td>SAS</td>\n",
       "      <td>6.0</td>\n",
       "      <td>476.0</td>\n",
       "      <td>960</td>\n",
       "      <td>0.496</td>\n",
       "      <td>82</td>\n",
       "      <td>37.7</td>\n",
       "      <td>25.6</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.762</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Charles Barkley</td>\n",
       "      <td>27</td>\n",
       "      <td>PHI</td>\n",
       "      <td>2.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>960</td>\n",
       "      <td>0.231</td>\n",
       "      <td>67</td>\n",
       "      <td>37.3</td>\n",
       "      <td>27.6</td>\n",
       "      <td>10.1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.722</td>\n",
       "      <td>13.4</td>\n",
       "      <td>0.258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karl Malone</td>\n",
       "      <td>27</td>\n",
       "      <td>UTA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>960</td>\n",
       "      <td>0.148</td>\n",
       "      <td>82</td>\n",
       "      <td>40.3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.770</td>\n",
       "      <td>15.5</td>\n",
       "      <td>0.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Clyde Drexler</td>\n",
       "      <td>28</td>\n",
       "      <td>POR</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>960</td>\n",
       "      <td>0.078</td>\n",
       "      <td>82</td>\n",
       "      <td>34.8</td>\n",
       "      <td>21.5</td>\n",
       "      <td>6.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.794</td>\n",
       "      <td>12.4</td>\n",
       "      <td>0.209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Kevin Johnson</td>\n",
       "      <td>24</td>\n",
       "      <td>PHO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>960</td>\n",
       "      <td>0.033</td>\n",
       "      <td>77</td>\n",
       "      <td>36.0</td>\n",
       "      <td>22.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>10.1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.843</td>\n",
       "      <td>12.7</td>\n",
       "      <td>0.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Dominique Wilkins</td>\n",
       "      <td>31</td>\n",
       "      <td>ATL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>960</td>\n",
       "      <td>0.030</td>\n",
       "      <td>81</td>\n",
       "      <td>38.0</td>\n",
       "      <td>25.9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.829</td>\n",
       "      <td>11.4</td>\n",
       "      <td>0.177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9T</td>\n",
       "      <td>Larry Bird</td>\n",
       "      <td>34</td>\n",
       "      <td>BOS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>960</td>\n",
       "      <td>0.026</td>\n",
       "      <td>60</td>\n",
       "      <td>38.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>8.5</td>\n",
       "      <td>7.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.891</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9T</td>\n",
       "      <td>Terry Porter</td>\n",
       "      <td>27</td>\n",
       "      <td>POR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>960</td>\n",
       "      <td>0.026</td>\n",
       "      <td>81</td>\n",
       "      <td>32.9</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.823</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Patrick Ewing</td>\n",
       "      <td>28</td>\n",
       "      <td>NYK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>960</td>\n",
       "      <td>0.021</td>\n",
       "      <td>81</td>\n",
       "      <td>38.3</td>\n",
       "      <td>26.6</td>\n",
       "      <td>11.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.745</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>John Stockton</td>\n",
       "      <td>28</td>\n",
       "      <td>UTA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>960</td>\n",
       "      <td>0.016</td>\n",
       "      <td>82</td>\n",
       "      <td>37.8</td>\n",
       "      <td>17.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>14.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.836</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Isiah Thomas</td>\n",
       "      <td>29</td>\n",
       "      <td>DET</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>960</td>\n",
       "      <td>0.011</td>\n",
       "      <td>48</td>\n",
       "      <td>34.5</td>\n",
       "      <td>16.2</td>\n",
       "      <td>3.3</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.782</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Robert Parish</td>\n",
       "      <td>37</td>\n",
       "      <td>BOS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>960</td>\n",
       "      <td>0.010</td>\n",
       "      <td>81</td>\n",
       "      <td>30.1</td>\n",
       "      <td>14.9</td>\n",
       "      <td>10.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.767</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Joe Dumars</td>\n",
       "      <td>27</td>\n",
       "      <td>DET</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>960</td>\n",
       "      <td>0.008</td>\n",
       "      <td>80</td>\n",
       "      <td>38.1</td>\n",
       "      <td>20.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.890</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Bernard King</td>\n",
       "      <td>34</td>\n",
       "      <td>WSB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>960</td>\n",
       "      <td>0.007</td>\n",
       "      <td>64</td>\n",
       "      <td>37.5</td>\n",
       "      <td>28.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.790</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Kenny Smith</td>\n",
       "      <td>25</td>\n",
       "      <td>HOU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>960</td>\n",
       "      <td>0.005</td>\n",
       "      <td>78</td>\n",
       "      <td>34.6</td>\n",
       "      <td>17.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>7.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.844</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Hakeem Olajuwon</td>\n",
       "      <td>28</td>\n",
       "      <td>HOU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>960</td>\n",
       "      <td>0.004</td>\n",
       "      <td>56</td>\n",
       "      <td>36.8</td>\n",
       "      <td>21.2</td>\n",
       "      <td>13.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.769</td>\n",
       "      <td>8.6</td>\n",
       "      <td>0.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19T</td>\n",
       "      <td>Tim Hardaway</td>\n",
       "      <td>24</td>\n",
       "      <td>GSW</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>960</td>\n",
       "      <td>0.001</td>\n",
       "      <td>82</td>\n",
       "      <td>39.2</td>\n",
       "      <td>22.9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.803</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0.148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19T</td>\n",
       "      <td>Kevin McHale</td>\n",
       "      <td>33</td>\n",
       "      <td>BOS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>960</td>\n",
       "      <td>0.001</td>\n",
       "      <td>68</td>\n",
       "      <td>30.4</td>\n",
       "      <td>18.4</td>\n",
       "      <td>7.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.829</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank             Player  Age   Tm  First  Pts Won  Pts Max  Share   G  \\\n",
       "0     1     Michael Jordan   27  CHI   77.0    891.0      960  0.928  82   \n",
       "1     2      Magic Johnson   31  LAL   10.0    497.0      960  0.518  79   \n",
       "2     3     David Robinson   25  SAS    6.0    476.0      960  0.496  82   \n",
       "3     4    Charles Barkley   27  PHI    2.0    222.0      960  0.231  67   \n",
       "4     5        Karl Malone   27  UTA    0.0    142.0      960  0.148  82   \n",
       "5     6      Clyde Drexler   28  POR    1.0     75.0      960  0.078  82   \n",
       "6     7      Kevin Johnson   24  PHO    0.0     32.0      960  0.033  77   \n",
       "7     8  Dominique Wilkins   31  ATL    0.0     29.0      960  0.030  81   \n",
       "8    9T         Larry Bird   34  BOS    0.0     25.0      960  0.026  60   \n",
       "9    9T       Terry Porter   27  POR    0.0     25.0      960  0.026  81   \n",
       "10   11      Patrick Ewing   28  NYK    0.0     20.0      960  0.021  81   \n",
       "11   12      John Stockton   28  UTA    0.0     15.0      960  0.016  82   \n",
       "12   13       Isiah Thomas   29  DET    0.0     11.0      960  0.011  48   \n",
       "13   14      Robert Parish   37  BOS    0.0     10.0      960  0.010  81   \n",
       "14   15         Joe Dumars   27  DET    0.0      8.0      960  0.008  80   \n",
       "15   16       Bernard King   34  WSB    0.0      7.0      960  0.007  64   \n",
       "16   17        Kenny Smith   25  HOU    0.0      5.0      960  0.005  78   \n",
       "17   18    Hakeem Olajuwon   28  HOU    0.0      4.0      960  0.004  56   \n",
       "18  19T       Tim Hardaway   24  GSW    0.0      1.0      960  0.001  82   \n",
       "19  19T       Kevin McHale   33  BOS    0.0      1.0      960  0.001  68   \n",
       "\n",
       "      MP   PTS   TRB   AST  STL  BLK    FG%    3P%    FT%    WS  WS/48  \n",
       "0   37.0  31.5   6.0   5.5  2.7  1.0  0.539  0.312  0.851  20.3  0.321  \n",
       "1   37.1  19.4   7.0  12.5  1.3  0.2  0.477  0.320  0.906  15.4  0.251  \n",
       "2   37.7  25.6  13.0   2.5  1.5  3.9  0.552  0.143  0.762  17.0  0.264  \n",
       "3   37.3  27.6  10.1   4.2  1.6  0.5  0.570  0.284  0.722  13.4  0.258  \n",
       "4   40.3  29.0  11.8   3.3  1.1  1.0  0.527  0.286  0.770  15.5  0.225  \n",
       "5   34.8  21.5   6.7   6.0  1.8  0.7  0.482  0.319  0.794  12.4  0.209  \n",
       "6   36.0  22.2   3.5  10.1  2.1  0.1  0.516  0.205  0.843  12.7  0.220  \n",
       "7   38.0  25.9   9.0   3.3  1.5  0.8  0.470  0.341  0.829  11.4  0.177  \n",
       "8   38.0  19.4   8.5   7.2  1.8  1.0  0.454  0.389  0.891   6.6  0.140  \n",
       "9   32.9  17.0   3.5   8.0  2.0  0.1  0.515  0.415  0.823  13.0  0.235  \n",
       "10  38.3  26.6  11.2   3.0  1.0  3.2  0.514  0.000  0.745  10.0  0.155  \n",
       "11  37.8  17.2   2.9  14.2  2.9  0.2  0.507  0.345  0.836  14.0  0.217  \n",
       "12  34.5  16.2   3.3   9.3  1.6  0.2  0.435  0.292  0.782   3.4  0.098  \n",
       "13  30.1  14.9  10.6   0.8  0.8  1.3  0.598  0.000  0.767  10.0  0.198  \n",
       "14  38.1  20.4   2.3   5.5  1.1  0.1  0.481  0.311  0.890   9.9  0.155  \n",
       "15  37.5  28.4   5.0   4.6  0.9  0.3  0.472  0.216  0.790   3.5  0.070  \n",
       "16  34.6  17.7   2.1   7.1  1.4  0.1  0.520  0.363  0.844   9.0  0.161  \n",
       "17  36.8  21.2  13.8   2.3  2.2  3.9  0.508  0.000  0.769   8.6  0.201  \n",
       "18  39.2  22.9   4.0   9.7  2.6  0.1  0.476  0.385  0.803   9.9  0.148  \n",
       "19  30.4  18.4   7.1   1.9  0.4  2.1  0.553  0.405  0.829   7.9  0.182  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mvp_1991 = pd.read_html(str(mvp_table))[0]\n",
    "\n",
    "mvp_1991"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above shows that we have successfully extracted the data for 1991. So we will do the same for the rest of the years and then merge the data frames into one dataset. All the data frames will be stored in a list called all_dfs.\n",
    "\n",
    "One observation I made is that is impossible to tell which data came from which year so I added the year column to the data frame to help with the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = []\n",
    "for year in years:\n",
    "    # read the HTML data\n",
    "    with open(\"MVP/{}.html\".format(year), encoding=\"utf-8\") as f:\n",
    "        page = f.read()\n",
    "\n",
    "        # create a parser class to extract table from the page\n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        # remove the top row of the table\n",
    "        soup.find(\"tr\", class_=\"over_header\").decompose()\n",
    "\n",
    "        # remove all other page elements and only find the specific table we want\n",
    "        mvp_table = soup.find(id=\"mvp\")\n",
    "\n",
    "        # read table into pandas dataframe\n",
    "        mvp = pd.read_html(str(mvp_table))[0]\n",
    "        \n",
    "        # create year column to know where data came from\n",
    "        mvp[\"Year\"] = year\n",
    "\n",
    "        all_dfs.append(mvp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then combine all of the dataframes into a single dataframe called mvps, which we save as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Player</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tm</th>\n",
       "      <th>First</th>\n",
       "      <th>Pts Won</th>\n",
       "      <th>Pts Max</th>\n",
       "      <th>Share</th>\n",
       "      <th>G</th>\n",
       "      <th>MP</th>\n",
       "      <th>PTS</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FT%</th>\n",
       "      <th>WS</th>\n",
       "      <th>WS/48</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9T</td>\n",
       "      <td>Anthony Mason</td>\n",
       "      <td>30</td>\n",
       "      <td>CHH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1150</td>\n",
       "      <td>0.006</td>\n",
       "      <td>73</td>\n",
       "      <td>43.1</td>\n",
       "      <td>16.2</td>\n",
       "      <td>11.4</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.745</td>\n",
       "      <td>11.4</td>\n",
       "      <td>0.173</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Glen Rice</td>\n",
       "      <td>30</td>\n",
       "      <td>CHH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1160</td>\n",
       "      <td>0.006</td>\n",
       "      <td>82</td>\n",
       "      <td>40.2</td>\n",
       "      <td>22.3</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.849</td>\n",
       "      <td>9.3</td>\n",
       "      <td>0.136</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Allen Iverson</td>\n",
       "      <td>27</td>\n",
       "      <td>PHI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1190</td>\n",
       "      <td>0.070</td>\n",
       "      <td>82</td>\n",
       "      <td>42.5</td>\n",
       "      <td>27.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.774</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.127</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>16T</td>\n",
       "      <td>Rasheed Wallace</td>\n",
       "      <td>24</td>\n",
       "      <td>POR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1180</td>\n",
       "      <td>0.001</td>\n",
       "      <td>49</td>\n",
       "      <td>28.9</td>\n",
       "      <td>12.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.732</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.169</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Kevin Garnett</td>\n",
       "      <td>22</td>\n",
       "      <td>MIN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1180</td>\n",
       "      <td>0.008</td>\n",
       "      <td>47</td>\n",
       "      <td>37.9</td>\n",
       "      <td>20.8</td>\n",
       "      <td>10.4</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.704</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.146</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank           Player  Age   Tm  First  Pts Won  Pts Max  Share   G    MP  \\\n",
       "8    9T    Anthony Mason   30  CHH    0.0      7.0     1150  0.006  73  43.1   \n",
       "10   11        Glen Rice   30  CHH    0.0      7.0     1160  0.006  82  40.2   \n",
       "5     6    Allen Iverson   27  PHI    0.0     83.0     1190  0.070  82  42.5   \n",
       "20  16T  Rasheed Wallace   24  POR    0.0      1.0     1180  0.001  49  28.9   \n",
       "9    10    Kevin Garnett   22  MIN    0.0      9.0     1180  0.008  47  37.9   \n",
       "\n",
       "     PTS   TRB  AST  STL  BLK    FG%    3P%    FT%    WS  WS/48  Year  \n",
       "8   16.2  11.4  5.7  1.0  0.5  0.525  0.333  0.745  11.4  0.173  1997  \n",
       "10  22.3   4.3  2.2  0.9  0.3  0.457  0.433  0.849   9.3  0.136  1998  \n",
       "5   27.6   4.2  5.5  2.7  0.2  0.414  0.277  0.774   9.2  0.127  2003  \n",
       "20  12.8   4.9  1.2  1.0  1.1  0.508  0.419  0.732   5.0  0.169  1999  \n",
       "9   20.8  10.4  4.3  1.7  1.8  0.460  0.286  0.704   5.4  0.146  1999  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mvps = pd.concat(all_dfs)\n",
    "\n",
    "pd.pandas.set_option('display.max_columns', None) #display all column names\n",
    "mvps.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we have gathered so far consists only of the players who have won the MVP award. We need all player stats to determine the properties associated with players who are likely to win the MVP award. For the next part of this project, we will download the player stats and also introduce selenium for scraping javascript pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section, we will extract data for all the players and their stats as well as team data.\n",
    "\n",
    "The following is the code used to extract data using the requests library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_stats_url = \"https://www.basketball-reference.com/leagues/NBA_{}_per_game.html\"\n",
    "\n",
    "url = player_stats_url.format(1991)\n",
    "data = requests.get(url)\n",
    "with open(\"PLAYERS/1991.html\", \"w+\", encoding=\"utf-8\") as f:\n",
    "    f.write(data.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The web page we intend to scrape loads the tables using javascript. As a result, the data scraped does not contain all the records we want. It only provides 17 rows, despite the fact that the table contains over 300 rows. To get around this problem, we'll use selenium.\n",
    "\n",
    "Selenium is a free, open-source software testing framework that allows developers to automate web browser actions. It is primarily used for testing web applications, but it can also be used for web scraping.\n",
    "\n",
    "One of the key advantages of Selenium is that it allows developers to control a real web browser, rather than just making HTTP requests like some other web scraping tools do. This means that it can interact with websites in the same way a user would, and can handle complex interactions such as JavaScript, cookies, and pop-ups.\n",
    "\n",
    "To use Selenium, you will need to have the following prerequisites installed on your system:\n",
    "\n",
    "A web browser\n",
    "The Selenium Python library\n",
    "A web driver\n",
    "\n",
    "After installation of the web driver, import selenium and create a variable to store the driver executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\cosic\\anaconda3\\lib\\site-packages (4.10.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\cosic\\anaconda3\\lib\\site-packages (from selenium) (2.0.3)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\cosic\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\cosic\\anaconda3\\lib\\site-packages (from selenium) (0.10.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\cosic\\anaconda3\\lib\\site-packages (from selenium) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\cosic\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (19.3.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\cosic\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.2.2)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\cosic\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: idna in c:\\users\\cosic\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.10)\n",
      "Requirement already satisfied: outcome in c:\\users\\cosic\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\cosic\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\cosic\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.14.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\cosic\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\cosic\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\cosic\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\cosic\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\cosic\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'executable_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-b42b9b7d1729>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mdriver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexecutable_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"PATH TO CHROMEDRIVER EXECUTABLE\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'executable_path'"
     ]
    }
   ],
   "source": [
    "#!pip install wheel\n",
    "#!pip install setuptools\n",
    "#!pip install pip\n",
    "\n",
    "!pip install selenium\n",
    "\n",
    "from selenium import webdriver\n",
    "\n",
    "driver = webdriver.Chrome(executable_path=\"PATH TO CHROMEDRIVER EXECUTABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the code above creates a new browser window that’s being controlled by selenium. We will use it to render a page with all the rows of data we need. As we did in Part 1, we will do it for one year to ensure that our program is working properly before creating a loop for all of the years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'driver' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-0856772bed43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# render url in the browser\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# add js to tell the browser to scroll down to be able to render the entire table\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'driver' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "year = 1991\n",
    "\n",
    "url = player_stats_url.format(year)\n",
    "\n",
    "# render url in the browser\n",
    "driver.get(url)\n",
    "\n",
    "# add js to tell the browser to scroll down to be able to render the entire table\n",
    "driver.execute_script(\"window.scrollTo(1, 1000)\")\n",
    "time.sleep(2)\n",
    "\n",
    "# get the html of the page\n",
    "html = driver.page_source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then download the HTML page containing all the 300+ rows. First I created a folder called PLAYERS that will contain all the HTML pages we will download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"PLAYERS/{}.html\".format(year), \"w+\", encoding=\"utf-8\") as f:\n",
    "    f.write(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the downloaded HTML page to confirm it captured all the rows in the table. If successful, create a loop to download the pages for all the years from 1991 to 2022. We use a time delay of 2 seconds because there are many rows of data being parsed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    url = player_stats_url.format(year)\n",
    "\n",
    "    # render url in the browser\n",
    "    driver.get(url)\n",
    "\n",
    "    # add js to tell the browser to scroll down to be able to render the entire table\n",
    "    driver.execute_script(\"window.scrollTo(1, 1000)\")\n",
    "    time.sleep(2)\n",
    "\n",
    "    # get the html of the page\n",
    "    html = driver.page_source\n",
    "    \n",
    "    with open(\"PLAYERS/{}.html\".format(year), \"w+\", encoding=\"utf-8\") as f:\n",
    "        f.write(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After downloading all the pages, it is now time to parse the stats with BeautifulSoup. When we look at the structure of the table, we realize that the row headers are repeated within the table after every 20 records.\n",
    "\n",
    "This will be a bit confusing when the table is loaded into pandas. Using the decompose() method, we will remove all of the header rows except the first one. Upon inspection, the header rows are in the <tr> tag with a class of header while the table has an id of pre_game_stats.\n",
    "\n",
    "The dataframes are stored in a list called player_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_df = []\n",
    "for year in years:\n",
    "\n",
    "    with open(\"PLAYERS/{}.html\".format(year), encoding=\"utf-8\") as f:\n",
    "        page = f.read()\n",
    "\n",
    "    # create a parser class to extract table from the page\n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "    # remove the top row of the table\n",
    "    soup.find(\"tr\", class_=\"thead\").decompose()\n",
    "\n",
    "    # remove all other page elements and only find the specific table we want\n",
    "    player_table = soup.find(id=\"per_game_stats\")\n",
    "\n",
    "    # convert the table into a string\n",
    "    # you'll get a list of dataframes so just get the first index.\n",
    "    player = pd.read_html(str(player_table))[0]\n",
    "    player[\"Year\"] = year\n",
    "    player_df.append(player)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use the pandas concat() function to combine all of the player stats before viewing a sample of the data to ensure it worked properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rk</th>\n",
       "      <th>Player</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tm</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>2P</th>\n",
       "      <th>2PA</th>\n",
       "      <th>2P%</th>\n",
       "      <th>eFG%</th>\n",
       "      <th>FT</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>ORB</th>\n",
       "      <th>DRB</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>267</td>\n",
       "      <td>Chris Mullin*</td>\n",
       "      <td>SF</td>\n",
       "      <td>33</td>\n",
       "      <td>GSW</td>\n",
       "      <td>79</td>\n",
       "      <td>63</td>\n",
       "      <td>34.6</td>\n",
       "      <td>5.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>.553</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>.411</td>\n",
       "      <td>4.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>.602</td>\n",
       "      <td>.605</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>.864</td>\n",
       "      <td>0.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>318</td>\n",
       "      <td>Bobby Phills</td>\n",
       "      <td>SG</td>\n",
       "      <td>30</td>\n",
       "      <td>CHH</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>29.5</td>\n",
       "      <td>5.4</td>\n",
       "      <td>12.0</td>\n",
       "      <td>.454</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>.330</td>\n",
       "      <td>4.4</td>\n",
       "      <td>8.7</td>\n",
       "      <td>.500</td>\n",
       "      <td>.499</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>.723</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>13.6</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>247</td>\n",
       "      <td>Jamaal Magloire</td>\n",
       "      <td>C</td>\n",
       "      <td>25</td>\n",
       "      <td>NOH</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>33.9</td>\n",
       "      <td>4.7</td>\n",
       "      <td>9.9</td>\n",
       "      <td>.473</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.000</td>\n",
       "      <td>4.7</td>\n",
       "      <td>9.9</td>\n",
       "      <td>.474</td>\n",
       "      <td>.473</td>\n",
       "      <td>4.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>.751</td>\n",
       "      <td>3.3</td>\n",
       "      <td>7.1</td>\n",
       "      <td>10.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>13.6</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>200</td>\n",
       "      <td>Eddie House</td>\n",
       "      <td>PG</td>\n",
       "      <td>31</td>\n",
       "      <td>BOS</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>16.9</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.4</td>\n",
       "      <td>.401</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>.383</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.1</td>\n",
       "      <td>.419</td>\n",
       "      <td>.500</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>.900</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>7.2</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>390</td>\n",
       "      <td>Jeff Teague</td>\n",
       "      <td>PG</td>\n",
       "      <td>22</td>\n",
       "      <td>ATL</td>\n",
       "      <td>70</td>\n",
       "      <td>7</td>\n",
       "      <td>13.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>.438</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>.375</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>.449</td>\n",
       "      <td>.467</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>.794</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Rk           Player Pos Age   Tm   G  GS    MP   FG   FGA   FG%   3P  \\\n",
       "368  267    Chris Mullin*  SF  33  GSW  79  63  34.6  5.5  10.0  .553  1.1   \n",
       "376  318     Bobby Phills  SG  30  CHH  28   9  29.5  5.4  12.0  .454  1.1   \n",
       "320  247  Jamaal Magloire   C  25  NOH  82  82  33.9  4.7   9.9  .473  0.0   \n",
       "251  200      Eddie House  PG  31  BOS  50   0  16.9  2.6   6.4  .401  1.3   \n",
       "551  390      Jeff Teague  PG  22  ATL  70   7  13.8  1.9   4.3  .438  0.3   \n",
       "\n",
       "     3PA   3P%   2P  2PA   2P%  eFG%   FT  FTA   FT%  ORB  DRB   TRB  AST  \\\n",
       "368  2.6  .411  4.5  7.5  .602  .605  2.3  2.7  .864  0.9  3.1   4.0  4.1   \n",
       "376  3.3  .330  4.4  8.7  .500  .499  1.7  2.3  .723  0.6  1.9   2.5  2.8   \n",
       "320  0.0  .000  4.7  9.9  .474  .473  4.3  5.7  .751  3.3  7.1  10.3  1.0   \n",
       "251  3.3  .383  1.3  3.1  .419  .500  0.7  0.8  .900  0.1  1.2   1.4  1.0   \n",
       "551  0.7  .375  1.6  3.7  .449  .467  1.1  1.4  .794  0.2  1.3   1.5  2.0   \n",
       "\n",
       "     STL  BLK  TOV   PF   PTS  Year  \n",
       "368  1.6  0.4  2.4  2.0  14.5  1997  \n",
       "376  1.5  0.3  1.7  2.6  13.6  2000  \n",
       "320  0.5  1.2  2.5  3.4  13.6  2004  \n",
       "251  0.6  0.1  0.5  1.2   7.2  2010  \n",
       "551  0.6  0.4  0.9  1.2   5.2  2011  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players = pd.concat(player_df)\n",
    "\n",
    "# view sample of data\n",
    "pd.pandas.set_option('display.max_columns', None) #display all column names\n",
    "players.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "players.to_csv(\"player_stats.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing we’ll do is scrape the team data. This will be important in helping us make predictions. The url we’ll use for this is below. The curly brace represents the year. The code downloads all the HTML pages from 1991 to 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_stats_url = \"https://www.basketball-reference.com/leagues/NBA_{}_standings.html\"\n",
    "\n",
    "# scraping the data\n",
    "for year in years:\n",
    "    url = team_stats_url.format(year)\n",
    "    data = requests.get(url)\n",
    "\n",
    "    with open(\"TEAM/{}.html\".format(year), \"w+\", encoding=\"utf-8\") as f:\n",
    "        f.write(data.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 separate tables that we need to scrape and we will do this using the BeautifulSoup Library. You can check the table elements using Inspect on your browser(Right click > Inspect)or Ctrl+Shift+I."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'decompose'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m     page \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m      6\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(page, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[43msoup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthead\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecompose\u001b[49m()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Eastern Conference\u001b[39;00m\n\u001b[1;32m     10\u001b[0m e_table \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdivs_standings_E\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'decompose'"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for year in years:\n",
    "    with open(\"TEAM/{}.html\".format(year), encoding=\"utf-8\") as f:\n",
    "        page = f.read()\n",
    "    \n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    soup.find('tr', class_=\"thead\").decompose()\n",
    "    \n",
    "    # Eastern Conference\n",
    "    e_table = soup.find_all(id=\"divs_standings_E\")[0]\n",
    "    e_df = pd.read_html(str(e_table))[0]\n",
    "    e_df[\"Year\"] = year\n",
    "    e_df[\"Team\"] = e_df[\"Eastern Conference\"]\n",
    "    del e_df[\"Eastern Conference\"]\n",
    "    dfs.append(e_df)\n",
    "    \n",
    "    # Western Conference\n",
    "    w_table = soup.find_all(id=\"divs_standings_W\")[0]\n",
    "    w_df = pd.read_html(str(w_table))[0]\n",
    "    w_df[\"Year\"] = year\n",
    "    w_df[\"Team\"] = w_df[\"Western Conference\"]\n",
    "    del w_df[\"Western Conference\"]\n",
    "    dfs.append(w_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams.to_csv(\"teams.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
